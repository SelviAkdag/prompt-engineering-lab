# =================================================================
# LLM Backend Configuration
# =================================================================
# Choose your backend: ollama (recommended) or openai
MODEL_BACKEND=ollama

# =================================================================
# Ollama Configuration (if MODEL_BACKEND=ollama)
# =================================================================
# Model to use with Ollama
# Recommended: llama3.2:3b (small, fast, good reasoning)
# Alternative: llama3.2:1b (faster, less capable)
#OLLAMA_MODEL=llama3.2:3b
OLLAMA_MODEL=llama3.2-long

# Ollama API endpoint (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# =================================================================
# OpenAI Configuration (if MODEL_BACKEND=openai)
# =================================================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# OpenAI model to use
OPENAI_MODEL=gpt-4o-mini